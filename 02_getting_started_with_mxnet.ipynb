{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_getting_started_with_mxnet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningMXNet/blob/master/02_getting_started_with_mxnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At65R3wNpAqc",
        "colab_type": "text"
      },
      "source": [
        "## Getting Started with MXNet: Training a NN on MNIST\n",
        "\n",
        "In this notebook, we train an artificial neural network on the MNIST dataset. We'll build a very simple neural network of 3 layers (input, hidden and output), and use dropout for regularization.\n",
        "\n",
        "As we saw in the previous notebook, Mxnet is not installed by default in Colab. So first, we need to find out the CUDA version Colab is using and then install the right Mxnet package for the CUDA version, as we did before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-ZvP86okM95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e7092b19-2fed-4d4a-fd1b-e5ec6dff1504"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCouxzmhQJJI",
        "colab_type": "text"
      },
      "source": [
        "Colab is using CUDA 10.0 so we need to install mxnet-cu100:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gkJnMtQlYL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCiM6UmcQV8c",
        "colab_type": "text"
      },
      "source": [
        "Now we'll import a couple of standard modules:\n",
        "\n",
        "- mxnet is the framework that we import as mx\n",
        "- nd is short for NDarray and is MXNet's primary tool for working with tensors\n",
        "- gluon includes several modules that we'll be using for training our network, such as data for downloading the dataset and loading the data into tensors, and loss for calculating the loss on each iteration.\n",
        "- autograd is tooll we use to automatically calculate the network's gradients w.r.t. the parameters\n",
        "- nn is a high-level API that will help us build our neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH103yBYllN1",
        "colab_type": "code",
        "outputId": "6b724160-7b5d-4753-a013-1d86e21546d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import mxnet as mx\n",
        "from mxnet import nd, gluon, autograd\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "import statistics\n",
        "\n",
        "print(mx.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS_xGX7ZFev8",
        "colab_type": "text"
      },
      "source": [
        "### MNIST Dataset\n",
        "\n",
        "We are going to work with the MNIST dataset. Basically it contains images of handwritten digits in grayscale, and its corresponding labels (one, two, three, etc).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Ps2Ca92Noe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# MXNet's default data convention is NCHW whereas\n",
        "# the MNIST Tensor's dimensions are NHWC\n",
        "\n",
        "def data_convention_normalization(data):\n",
        "    \"\"\"HWC -> CHW; Move the channel axis (2) to the first axis (0)\"\"\"\n",
        "    return nd.moveaxis(data, 2, 0).astype('float32') / 255\n",
        "\n",
        "\n",
        "train_data = gluon.data.vision.MNIST(train=True).transform_first(data_convention_normalization)\n",
        "val_data = gluon.data.vision.MNIST(train=False).transform_first(data_convention_normalization)\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(val_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAXnnPoT4C3q",
        "colab_type": "code",
        "outputId": "ba79ba97-2aa6-4770-cb58-11416dbf2842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_loader = gluon.data.DataLoader(train_data, shuffle=True, batch_size=64)\n",
        "val_loader = gluon.data.DataLoader(val_data, shuffle=False, batch_size=64)\n",
        "\n",
        "for X, y in train_loader:\n",
        "    pass\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 1, 28, 28)\n",
            "(32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rk0WhwYmOaZ",
        "colab_type": "code",
        "outputId": "51c0dcb0-4a00-44b4-ddab-63220d7c2720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "drop_prob = 0.2\n",
        "\n",
        "net = nn.Sequential()\n",
        "net.add(nn.Flatten(),\n",
        "        nn.Dense(128, activation='relu'),\n",
        "        nn.Dropout(drop_prob),\n",
        "        nn.Dense(10))\n",
        "\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten\n",
              "  (1): Dense(None -> 128, Activation(relu))\n",
              "  (2): Dropout(p = 0.2, axes=())\n",
              "  (3): Dense(None -> 10, linear)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGL5yOzKxOpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu(0)\n",
        "net.initialize(mx.init.Xavier(), ctx=ctx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOYmG5Wyxu7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = gluon.Trainer(\n",
        "    params=net.collect_params(),\n",
        "    optimizer='sgd',\n",
        "    optimizer_params={'learning_rate': 0.04},\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5DOYC3KyHym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metric = mx.metric.Accuracy()\n",
        "loss_function = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQtFddDIgyB8",
        "colab_type": "code",
        "outputId": "86cc85d1-14f8-4bf1-9782-ac0b13fbc422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    batch_train_loss = []\n",
        "    \n",
        "    for batch, labels in train_loader:\n",
        "        \n",
        "        batch = batch.as_in_context(ctx)\n",
        "        labels = labels.as_in_context(ctx)\n",
        "        \n",
        "        with autograd.record():\n",
        "            predictions = net(batch)\n",
        "            loss = loss_function(predictions, labels)\n",
        "            \n",
        "        loss.backward()\n",
        "        metric.update(labels, predictions)\n",
        "        \n",
        "        trainer.step(batch_size=batch.shape[0])\n",
        "        \n",
        "        batch_train_loss.append(float(nd.sum(loss).asscalar()))\n",
        "        \n",
        "    batch_loss = statistics.mean(batch_train_loss)\n",
        "    \n",
        "    name, acc = metric.get()\n",
        "    \n",
        "    \n",
        "    print('Loss on epoch {}: {}'.format(epoch + 1, batch_loss))\n",
        "    print('Accuracy on epoch {}: {} = {}'.format(epoch + 1, name, acc))\n",
        "    metric.reset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss on epoch 1: 35.97205144560922\n",
            "Accuracy on epoch 1: accuracy = 0.8427\n",
            "Loss on epoch 2: 19.732611071580507\n",
            "Accuracy on epoch 2: accuracy = 0.91225\n",
            "Loss on epoch 3: 16.276260242787504\n",
            "Accuracy on epoch 3: accuracy = 0.92775\n",
            "Loss on epoch 4: 13.957860258596538\n",
            "Accuracy on epoch 4: accuracy = 0.9380333333333334\n",
            "Loss on epoch 5: 12.52040814235012\n",
            "Accuracy on epoch 5: accuracy = 0.9456166666666667\n",
            "Loss on epoch 6: 11.38861847686361\n",
            "Accuracy on epoch 6: accuracy = 0.9499166666666666\n",
            "Loss on epoch 7: 10.330693055698866\n",
            "Accuracy on epoch 7: accuracy = 0.9547166666666667\n",
            "Loss on epoch 8: 9.653635325081058\n",
            "Accuracy on epoch 8: accuracy = 0.9561166666666666\n",
            "Loss on epoch 9: 9.079066785668005\n",
            "Accuracy on epoch 9: accuracy = 0.9591666666666666\n",
            "Loss on epoch 10: 8.574628519986485\n",
            "Accuracy on epoch 10: accuracy = 0.9611166666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9M_K-5PMKnY",
        "colab_type": "code",
        "outputId": "6ecb850e-f0f5-420f-8800-99b8732b390c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "metric = mx.metric.Accuracy()\n",
        "for batch, labels in val_loader:\n",
        "    batch = batch.as_in_context(ctx)\n",
        "    labels = labels.as_in_context(ctx)\n",
        "    metric.update(labels, net(batch))\n",
        "    \n",
        "print('Validation: {} = {}'.format(*metric.get()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation: accuracy = 0.9685\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}