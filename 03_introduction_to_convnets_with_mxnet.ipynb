{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_introduction_to_convnets_with_mxnet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningMXNet/blob/master/03_introduction_to_convnets_with_mxnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx2LMiaPLoYO",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to Convolutional Neural Networks with MXNet\n",
        "\n",
        "We previously trained an artificial neural network on the MNIST dataset, now we'll introduce the convolutional neural networks (CNNs or Convnets for short). CNNs are part of the world of deep learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBaWG-3uKPh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5MHnLRfNJnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3xK19PbOnk9",
        "colab_type": "code",
        "outputId": "1faa0fba-7e88-4484-80e2-a3d802203262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import mxnet as mx\n",
        "from mxnet import nd, gluon, autograd\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "import statistics\n",
        "\n",
        "\n",
        "print(mx.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57Yk4yHuO7Pr",
        "colab_type": "text"
      },
      "source": [
        "### MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfYNedeoO-si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://beta.mxnet.io/api/gluon/_autogen/mxnet.gluon.data.vision.transforms.ToTensor.html\n",
        "# (HxWxC), [0, 255] -> (CxHxW), [0, 1)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "MNIST = gluon.data.vision.MNIST\n",
        "\n",
        "train_data = MNIST(train=True).transform_first(transform)\n",
        "valid_data = MNIST(train=False).transform_first(transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKKsMQYbQknB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e6812788-dd71-4611-9929-0c89d5dff81c"
      },
      "source": [
        "train_loader = gluon.data.DataLoader(train_data, shuffle=True, batch_size=64)\n",
        "valid_loader = gluon.data.DataLoader(valid_data, shuffle=False, batch_size=64)\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "\n",
        "batch, labels = dataiter.__next__()\n",
        "\n",
        "print(batch.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 1, 28, 28)\n",
            "(64,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0FR5If1mqbD",
        "colab_type": "text"
      },
      "source": [
        "### Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9W4BzdsjZeN",
        "colab_type": "code",
        "outputId": "75168df3-9f0a-437f-c519-c41c2cb9d588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "convnet = nn.Sequential()\n",
        "\n",
        "convnet.add(\n",
        "    nn.Conv2D(channels=32, kernel_size=3, activation='relu'),\n",
        "    nn.MaxPool2D(pool_size=2),\n",
        "    nn.Conv2D(channels=64, kernel_size=3, activation='relu'),\n",
        "    nn.MaxPool2D(pool_size=2),\n",
        "    nn.Conv2D(channels=64, kernel_size=3, activation='relu'),\n",
        "    nn.Dense(64, activation='relu'),\n",
        "    nn.Dense(10)\n",
        ")\n",
        "\n",
        "convnet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2D(None -> 32, kernel_size=(3, 3), stride=(1, 1), Activation(relu))\n",
              "  (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCHW)\n",
              "  (2): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1), Activation(relu))\n",
              "  (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCHW)\n",
              "  (4): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1), Activation(relu))\n",
              "  (5): Dense(None -> 64, Activation(relu))\n",
              "  (6): Dense(None -> 10, linear)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAtEBG72rpY4",
        "colab_type": "code",
        "outputId": "135d660f-de06-4473-fe8a-66485e943573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu(0)\n",
        "convnet.initialize(mx.init.Xavier(), ctx=ctx)\n",
        "convnet.summary(nd.zeros((1, 1, 28, 28), ctx=ctx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "        Layer (type)                                Output Shape         Param #\n",
            "================================================================================\n",
            "               Input                              (1, 1, 28, 28)               0\n",
            "        Activation-1                     <Symbol conv0_relu_fwd>               0\n",
            "        Activation-2                             (1, 32, 26, 26)               0\n",
            "            Conv2D-3                             (1, 32, 26, 26)             320\n",
            "         MaxPool2D-4                             (1, 32, 13, 13)               0\n",
            "        Activation-5                     <Symbol conv1_relu_fwd>               0\n",
            "        Activation-6                             (1, 64, 11, 11)               0\n",
            "            Conv2D-7                             (1, 64, 11, 11)           18496\n",
            "         MaxPool2D-8                               (1, 64, 5, 5)               0\n",
            "        Activation-9                     <Symbol conv2_relu_fwd>               0\n",
            "       Activation-10                               (1, 64, 3, 3)               0\n",
            "           Conv2D-11                               (1, 64, 3, 3)           36928\n",
            "       Activation-12                    <Symbol dense0_relu_fwd>               0\n",
            "       Activation-13                                     (1, 64)               0\n",
            "            Dense-14                                     (1, 64)           36928\n",
            "            Dense-15                                     (1, 10)             650\n",
            "================================================================================\n",
            "Parameters in forward computation graph, duplicate included\n",
            "   Total params: 93322\n",
            "   Trainable params: 93322\n",
            "   Non-trainable params: 0\n",
            "Shared params in forward computation graph: 0\n",
            "Unique parameters in model: 93322\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzRPKI9ZvzkZ",
        "colab_type": "text"
      },
      "source": [
        "### Trainer: Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiMQF9BkskbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = gluon.Trainer(\n",
        "    params=convnet.collect_params(),\n",
        "    optimizer='sgd',\n",
        "    optimizer_params={'learning_rate': 0.04},\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a86Mfx5q6bT",
        "colab_type": "text"
      },
      "source": [
        "**Train function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onvNDqIPi94y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_function, optimizer):\n",
        "    \n",
        "    train_batch_losses = []\n",
        "    \n",
        "    for batch, labels in train_loader:\n",
        "        batch = batch.as_in_context(ctx)\n",
        "        labels = labels.as_in_context(ctx)\n",
        "        \n",
        "        with autograd.record():\n",
        "            output = model(batch)\n",
        "            loss = loss_function(output, labels)\n",
        "            \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step(batch_size=batch.shape[0])\n",
        "        \n",
        "        train_batch_losses.append(float(nd.sum(loss).asscalar()))\n",
        "        \n",
        "    mean_loss = statistics.mean(train_batch_losses)\n",
        "    \n",
        "    return mean_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLEj_u94rD0n",
        "colab_type": "text"
      },
      "source": [
        "**Validation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrBt3KaNk3Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, loss_function, optimizer):\n",
        "    \n",
        "    validation_batch_losses = []\n",
        "    \n",
        "    for batch, labels in valid_loader:\n",
        "        batch = batch.as_in_context(ctx)\n",
        "        labels = labels.as_in_context(ctx)\n",
        "        \n",
        "        output = model(batch)\n",
        "        \n",
        "        loss = loss_function(output, labels)\n",
        "        \n",
        "        validation_batch_losses.append(float(nd.sum(loss).asscalar()))\n",
        "        \n",
        "        mean_loss = statistics.mean(validation_batch_losses)\n",
        "        \n",
        "    return mean_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4XwJTsprHQw",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7T5Ui4TpvLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, loader):\n",
        "    \n",
        "    metric = mx.metric.Accuracy()\n",
        "    \n",
        "    for batch, labels in loader:\n",
        "        batch = batch.as_in_context(ctx)\n",
        "        labels = labels.as_in_context(ctx)\n",
        "        \n",
        "        class_probabilities = nd.softmax(model(batch), axis=1)\n",
        "        \n",
        "        predictions = nd.argmax(class_probabilities, axis=1)\n",
        "        \n",
        "        metric.update(labels, predictions)\n",
        "        \n",
        "    _, accuracy_metric = metric.get()\n",
        "    \n",
        "    return accuracy_metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs3mCDQZFseL",
        "colab_type": "text"
      },
      "source": [
        "### Training the Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4ji8CPBuF2g",
        "colab_type": "code",
        "outputId": "f1a73e47-32ec-42e1-dd6a-f10c9ead9139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "loss_function = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(1, 1 + epochs):\n",
        "    \n",
        "    print('Epoch {}/{}'.format(epoch, epochs))\n",
        "    \n",
        "    train_loss = train(convnet, loss_function, trainer)\n",
        "    train_accuracy = accuracy(convnet, train_loader)\n",
        "    \n",
        "    print('Training loss: {}'.format(train_loss))\n",
        "    print('Training accuracy: {}%'.format(train_accuracy * 100))\n",
        "    \n",
        "    valid_loss = validate(convnet, loss_function, trainer)\n",
        "    valid_accuracy = accuracy(convnet, valid_loader)\n",
        "    \n",
        "    print('Validation loss: {}'.format(valid_loss))\n",
        "    print('Validation accuracy: {}%'.format(valid_accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Training loss: 4.350311624946625\n",
            "Training accuracy: 98.22666666666666%\n",
            "Validation loss: 3.3219563202208775\n",
            "Validation accuracy: 98.37%\n",
            "Epoch 2/10\n",
            "Training loss: 3.41099478887406\n",
            "Training accuracy: 97.87833333333333%\n",
            "Validation loss: 4.370452936964145\n",
            "Validation accuracy: 97.72999999999999%\n",
            "Epoch 3/10\n",
            "Training loss: 2.9088058139302775\n",
            "Training accuracy: 98.38%\n",
            "Validation loss: 3.621938658913799\n",
            "Validation accuracy: 98.16%\n",
            "Epoch 4/10\n",
            "Training loss: 2.4454577407126488\n",
            "Training accuracy: 98.97166666666666%\n",
            "Validation loss: 2.503656580534046\n",
            "Validation accuracy: 98.79%\n",
            "Epoch 5/10\n",
            "Training loss: 2.0874024605803463\n",
            "Training accuracy: 99.05666666666667%\n",
            "Validation loss: 2.5217852653293416\n",
            "Validation accuracy: 98.79%\n",
            "Epoch 6/10\n",
            "Training loss: 1.7922539590482613\n",
            "Training accuracy: 99.21333333333334%\n",
            "Validation loss: 2.3535762271416747\n",
            "Validation accuracy: 98.72%\n",
            "Epoch 7/10\n",
            "Training loss: 1.638567416424325\n",
            "Training accuracy: 99.45%\n",
            "Validation loss: 2.2032792256154403\n",
            "Validation accuracy: 98.88%\n",
            "Epoch 8/10\n",
            "Training loss: 1.4520793749150565\n",
            "Training accuracy: 99.24666666666667%\n",
            "Validation loss: 2.440410527697272\n",
            "Validation accuracy: 98.7%\n",
            "Epoch 9/10\n",
            "Training loss: 1.3226584282908231\n",
            "Training accuracy: 99.54333333333332%\n",
            "Validation loss: 2.05486644726472\n",
            "Validation accuracy: 98.97%\n",
            "Epoch 10/10\n",
            "Training loss: 1.1522220314246043\n",
            "Training accuracy: 99.58333333333333%\n",
            "Validation loss: 2.2442952650584354\n",
            "Validation accuracy: 98.91%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}